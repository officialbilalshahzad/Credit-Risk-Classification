# -*- coding: utf-8 -*-
"""logistic_regression.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1v4LLOh1lpHrptIkUPTpn6nfaZWY1BRjL
"""

from google.colab import files
uploaded = files.upload()

from google.colab import files
uploaded = files.upload() # Re-upload the file to ensure it's available

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler # Crucial for scaling features
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report

# --- 1. DATA PREPARATION ---
# Load the dataset
credit_data = pd.read_csv("credit_data.csv")

# Impute missing values (filling NaNs with the mean is a simple approach)
# This ensures no rows are dropped due to missing data.
for col in ["income", "age", "loan"]:
    if credit_data[col].isnull().any():
        credit_data[col] = credit_data[col].fillna(credit_data[col].mean())

# Define Features (X) and Target (Y)
# Features are the inputs the model uses to predict the target.
features = credit_data[["income", "age", "loan"]]
target = credit_data['default'] # Target is the outcome (0: No Default, 1: Default)

# Split the data into Training and Testing sets (70% Train, 30% Test)
# random_state ensures the split is the same every time you run the code.
features_train, features_test, target_train, target_test = train_test_split(
    features, target, test_size=0.3, random_state=42
)

# --- 2. FEATURE SCALING (ESSENTIAL FOR LOGISTIC REGRESSION) ---
# Standardization brings all features (like high income and low age) to a similar scale,
# ensuring no single feature dominates the distance/coefficient calculation.
scaler = StandardScaler()

# Fit the scaler ONLY on the training data to prevent data leakage
features_train_scaled = scaler.fit_transform(features_train)

# Transform the test data using the parameters learned from the training data
features_test_scaled = scaler.transform(features_test)

# --- 3. MODEL TRAINING ---
# Initialize and train the Logistic Regression model
model = LogisticRegression()
model.fit(features_train_scaled, target_train)

# Make predictions on the scaled test set
predictions = model.predict(features_test_scaled)


# --- 4. MODEL EVALUATION AND VISUALIZATION ---

print("="*40)
print("  LOAN DEFAULT PREDICTION MODEL RESULTS")
print("="*40)

# 4.1. Accuracy Score
acc_score = accuracy_score(target_test, predictions)
print(f"Overall Accuracy Score: {acc_score:.4f}")
print("\n")

# 4.2. Classification Report (Detailed Metrics)
# Important for checking Precision and Recall, which are more critical than pure Accuracy.
print("--- Detailed Classification Report ---")
print(classification_report(target_test, predictions))
print("\n")


# 4.3. Confusion Matrix Visualization (Key Image for GitHub)
cm = confusion_matrix(target_test, predictions)
plt.figure(figsize=(7, 6))
sns.heatmap(
    cm,
    annot=True, # Display the numbers
    fmt='d',     # Format as integer
    cmap='Blues', # Color scheme
    cbar=False,
    xticklabels=['Predicted: No Default (0)', 'Predicted: Default (1)'],
    yticklabels=['Actual: No Default (0)', 'Actual: Default (1)']
)
plt.title('Confusion Matrix Heatmap (Visualizing Model Errors)')
plt.ylabel('True Label (Actual Outcome)')
plt.xlabel('Predicted Label (Model Guess)')
plt.show()


# --- 5. PREDICTING A NEW CUSTOMER (LIVE DEMO) ---

# Define a new high-income, high-loan customer
new_customer = pd.DataFrame({
    'income': [200000],
    'age': [30],
    'loan': [50000]
})

# IMPORTANT: The new customer data MUST be scaled using the same 'scaler' object
new_customer_scaled = scaler.transform(new_customer)

# Make prediction
predicted_default = model.predict(new_customer_scaled)
probability = model.predict_proba(new_customer_scaled)

print("--- New Customer Prediction ---")
print(f"Customer Features:\n{new_customer.iloc[0].to_dict()}")
print(f"Predicted Default (0=No, 1=Yes): {predicted_default[0]}")
print(f"Probability of Default (1): {probability[0][1]:.2f} (Confidence Level)")

# Interpretation of the prediction
if predicted_default[0] == 1:
    print("\nResult: Loan should be DENIED (High predicted risk of default).")
else:
    print("\nResult: Loan can be APPROVED (Low predicted risk of default).")